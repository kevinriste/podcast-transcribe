# Podcast transcription service

## Purpose

I created this in order to consume Substack subscriptions in the form of a podcast, because I'm much more effective at listening to podcasts than I am at reading emails.

## How it works

- `process-caller.sh` is the cron entrypoint and adds timestamps to logs.
- `process.sh` orchestrates the pipeline every 20 minutes:
  - IMAP parsing (`imap/parse_email.py`) downloads unseen emails and writes text inputs with metadata headers.
  - RSS parsing (`rss/check-rss.py`) reads `rss/feeds.txt`, fetches new items, and writes text inputs with metadata headers.
  - Archives a copy of text inputs to `text-to-speech/input-text-archive`.
  - Google TTS (`text-to-speech/text_to_speech.py`) chunks text, generates MP3s, writes ID3 tags, and moves audio into `dropcaster-docker/audio`.
  - Dropcaster renders the RSS feed when audio changes.
  - Audio older than 8 weeks is archived to `dropcaster-docker/audio-archive` before Dropcaster runs.

Optional scripts:
- None (OpenAI/AWS TTS scripts removed).

## Runtime requirements

- Ubuntu + cron (current schedule: `*/20 * * * * bash -l /home/flog99/dev/podcast-transcribe/process-caller.sh >> /home/flog99/process-log.log 2>&1`)
- Docker + Docker Compose (Dropcaster and nginx-proxy stack).
- Python via `pyenv` + `uv` for IMAP/RSS/Google TTS (pyproject requires >=3.9).
- Playwright browsers installed for IMAP/RSS fetches.
- `ffmpeg` available on PATH (required by `pydub`).
- Local article scraper services:
  - IMAP link mode: `http://localhost:3001/fetch?url=...`
  - RSS fetcher: `http://localhost:3002/fetch?url=...`

## Intake methods (end-to-end)

### Email: plain newsletters (Substack/Beehiiv/other)
1) `imap/parse_email.py` reads unread IMAP messages.
2) Email text is cleaned; Beehiiv sources are converted to plain text.
3) A source URL is extracted from the email HTML.
   - Substack: chooses the post link and cleans it to `publication_id` + `post_id`.
   - Beehiiv: uses the “Read Online” link and displays the sender name.
   - Unknown sources: sends a Gotify notification and leaves the source URL blank.
4) Metadata is prepended to the text input:
   - `META_TITLE`, `META_SOURCE_URL`, `META_SOURCE_KIND`
5) The text is written to `text-to-speech/text-input/*.txt`.

### Email: "link" subject (full article fetch)
1) `imap/parse_email.py` treats the email body as a URL.
2) The URL is fetched via the local scraper (`http://localhost:3001/fetch`).
3) Metadata is prepended (`META_TITLE`, `META_SOURCE_URL`, `META_SOURCE_KIND=url`).
4) The article text is written to `text-to-speech/text-input/*.txt`.

### Email: "youtube" subject
1) `imap/parse_email.py` treats the email body as a YouTube URL.
2) `yt-dlp` downloads audio and converts it to MP3.
3) A summary is generated from the YouTube description.
4) ID3 tags are written directly to the MP3 (description + source link).

### RSS feeds
1) `rss/check-rss.py` polls feeds in `rss/feeds.txt`.
2) For NYT feeds, it uses the local scraper and (if needed) Wayback Machine.
3) For other feeds, it extracts text from RSS entry content.
4) Metadata is prepended and written to `text-to-speech/text-input/*.txt`.
5) Feed GUIDs are tracked in `rss/feed-guids/` to avoid reprocessing.

## Text-to-speech (Google path)
1) `text-to-speech/text_to_speech.py` reads `text-to-speech/text-input/*.txt`.
2) Metadata is parsed and stripped from the content.
3) The content is cleaned and chunked (3–5k characters per request).
4) A 2–3 sentence summary is generated by `gpt-5-mini`.
5) The description is assembled:
   - Summary
   - `Title: <title>`
   - `Source: <a href="...">...</a>`
6) MP3 chunks are stitched into a single file and saved in `dropcaster-docker/audio`.
7) ID3 tags are written (title + description + source URL).

## Cleaning details

### Email cleaning (`imap/parse_email.py`)
Plain newsletter text is normalized before writing to the text input file:
- If the sender is Beehiiv (`x-beehiiv-ids`), convert markdown to HTML and extract plain text.
- Strip all URLs using a URL regex.
- Remove empty bracket pairs: `[]`, `()`, `<>`.
- Prefix the body with `From.` and `Subject.` lines (using the unstripped subject).

### TTS cleaning (`text-to-speech/text_to_speech.py`)
The Google TTS script applies these transformations in order:
- Remove runs of 3+ dashes (`---` → ``).
- Remove all URLs using a URL regex.
- Remove empty bracket pairs: `[]`, `()`, `<>`.
- Collapse non-newline whitespace to single spaces.
- Remove the “Unsubscribe” section if it appears after a blank line.
- Remove “View this post on the web at” intro text.
- Remove Beehiiv’s “plain text version” disclaimer text.
- Remove a specific social-links block used by some newsletters (Facebook/Twitter/LinkedIn lines).
- Remove Beehiiv image caption blocks (`View image: ... Caption: ...`).
- Replace “Keynesian” with “Cainzeean” (pronunciation fix).
- Add punctuation at line ends so narration pauses (`<word>\n` → `<word>.\n`).

## Paths

- Text inputs: `text-to-speech/text-input`
- Empty inputs: `text-to-speech/text-input-empty-files`
- Oversized inputs: `text-to-speech/text-input-too-big`
- Input text archive: `text-to-speech/input-text-archive`
- RSS GUID tracking: `rss/feed-guids/`
- Audio output: `dropcaster-docker/audio`
- Archive: `dropcaster-docker/audio-archive`
- Logs (cron): `/home/flog99/process-log.log`

## Summaries and descriptions

- Summary model: `gpt-5-mini` (2–3 sentences).
- Google TTS builds the ID3 description as:
  - Summary
  - `Title: <title>`
  - `Source: <a href="...">...</a>`
  - Separator: `<br/><br/>`
- OpenAI/AWS TTS scripts were removed; summaries/ID3 tags are handled by the Google TTS path.

## Environment variables and credentials

Core pipeline:
- `GMAIL_PODCAST_ACCOUNT`, `GMAIL_PODCAST_ACCOUNT_APP_PASSWORD`
- `OPENAI_API_KEY` (summaries)
- `GOTIFY_SERVER`, `GOTIFY_TOKEN`
- `PODCAST_DOMAIN_PRIMARY`, `PODCAST_DOMAIN_SECONDARY`
- `GOOGLE_APPLICATION_CREDENTIALS` (path to the Google TTS service account JSON; `process.sh` exports this)

nginx-proxy + ACME:
- `GMAIL_PRIMARY_ACCOUNT` (DEFAULT_EMAIL for ACME)
- `CF_TOKEN`, `CF_ACCOUNT_ID` (Cloudflare DNS-01 challenge)

## Manual runs

- IMAP parser: `cd imap && /home/flog99/.local/bin/uv run python3 parse_email.py`
- RSS parser: `cd rss && /home/flog99/.local/bin/uv run python3 check-rss.py`
- Google TTS: `cd text-to-speech && /home/flog99/.local/bin/uv run python3 text_to_speech.py`
